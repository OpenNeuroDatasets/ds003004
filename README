The study attempts to show how one can classify emotion states from acquired electroencephalographic (EEG) data, and its possible relevance to finding new methods of reducing anxiety, stress, depression, and anger management. During the study, subjects listen to voice recordings that suggest an emotional feeling and ask subjects to imagine an emotional scenario or to recall an experience in which they have felt that emotion before. The study uses 15 different emotion narratives, each of which suggest an emotion that is either of positive valence (e.g., joy, happiness) or of negative valence (e.g., sadness, anger). When the subject first begins to feel filled with the suggested emotion, they indicate this by pressing the finger pressure sensor. Subjects were instructed to "feel" the emotion for approximately 3-5 minutes; however, no external time cues were provided so actual time spent in each emotion following the "feeling it" button press vary. 

Raw data has been preprocessed to fix bad event codes and remove bad channels for usability. High pass filter at 1Hz was also applied to make the data ready for running ICA.